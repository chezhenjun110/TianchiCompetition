{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#### calculate miss values\n",
    "def col_miss(train_df):\n",
    "    col_missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
    "    col_missing_df.columns = ['col','missing_count']\n",
    "    col_missing_df = col_missing_df.sort_values(by='missing_count')\n",
    "    return col_missing_df\n",
    "\n",
    "#### obtain cols of XX type\n",
    "def obtain_x(train_df,xtype):\n",
    "    dtype_df = train_df.dtypes.reset_index()\n",
    "    dtype_df.columns = ['col','type']\n",
    "    return dtype_df[dtype_df.type==xtype].col.values\n",
    "\n",
    "def date_cols(train_df,float_col):\n",
    "    float_date_col = []\n",
    "    for col in float_col:\n",
    "        if train_df[col].min() > 1e13:\n",
    "            float_date_col.append(col)\n",
    "    return float_date_col\n",
    "\n",
    "def float_uniq(float_df,float_col):\n",
    "    float_uniq_col = []\n",
    "    for col in float_col:\n",
    "        uniq = float_df[col].unique()\n",
    "        if len(uniq) == 1:\n",
    "            float_uniq_col.append(col)\n",
    "    return float_uniq_col\n",
    "\n",
    "def cal_corrcoef(float_df,y_train,float_col):\n",
    "    corr_values = []\n",
    "    for col in float_col:\n",
    "        corr_values.append(abs(np.corrcoef(float_df[col].values,y_train)[0,1]))\n",
    "    corr_df = pd.DataFrame({'col':float_col,'corr_value':corr_values})\n",
    "    corr_df = corr_df.sort_values(by='corr_value',ascending=False)\n",
    "    return corr_df\n",
    "\n",
    "def build_model(x_train,y_train):\n",
    "    reg_model = LinearRegression()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the number of miss values\n",
    "col_missing_df = col_miss(train_df)\n",
    "# del cols of all nan\n",
    "all_nan_columns = col_missing_df[col_missing_df.missing_count==499].col.values\n",
    "train_df.drop(all_nan_columns,axis=1,inplace=True)\n",
    "# obtain float cols\n",
    "float64_col = obtain_x(train_df,'float64')\n",
    "# del cols that miss number greater than 200\n",
    "miss_float = train_df[float64_col].isnull().sum(axis=0).reset_index()\n",
    "miss_float.columns = ['col','count']\n",
    "miss_float_almost = miss_float[miss_float['count']>200].col.values\n",
    "float64_col = float64_col.tolist()\n",
    "float64_col = [col for col in float64_col if col not in miss_float_almost]\n",
    "# del date cols\n",
    "float64_date_col = date_cols(train_df,float64_col)\n",
    "float64_col = [col for col in float64_col if col not in float64_date_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_df = train_df[float64_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median=float_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_df.fillna(median,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del cols which unique eq. 1\n",
    "float64_uniq_col = float_uniq(float_df,float64_col)\n",
    "float64_col = [col for col in float64_col if col not in float64_uniq_col]\n",
    "# obtained corrcoef greater than 0.2\n",
    "float64_col.remove('Y')\n",
    "y_train = train_df.Y.values\n",
    "corr_df = cal_corrcoef(float_df,y_train,float64_col)\n",
    "corr02 = corr_df[corr_df.corr_value>=0.2]\n",
    "corr02_col = corr02['col'].values.tolist()\n",
    "x_train = float_df[corr02_col].values\n",
    "test_df = pd.read_excel('testA.xlsx')\n",
    "sub_test = test_df[corr02_col].copy()\n",
    "sub_test.fillna(sub_test.median(),inplace=True)\n",
    "x_test = sub_test.values\n",
    "X = np.vstack((x_train,x_test))\n",
    "X = preprocessing.scale(X)\n",
    "x_train = X[0:len(x_train)]\n",
    "x_test = X[len(x_train):]\n",
    "model = build_model(x_train,y_train)\n",
    "subA = model.predict(x_test)\n",
    "# read submit data\n",
    "sub_df = pd.read_csv('subA.csv',header=None)\n",
    "sub_df['Y'] = subA\n",
    "sub_df.to_csv('github.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.035890758033725143"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_scores = cross_val_score(model, x_train, y_train,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "np.mean(lin_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
